# Documentation : Stratégies de NER

## Expressions régulières

Objectif : exploiter la liste alphabétique des noms de personne.  

![liste_alpha](images/table_alpha.jpg)

### Programme Regex

Les paramètres du programme se trouvent dans le programme ```params.py```. Tout est construit autour du document ```datadoc``` généré par le programme ```creation_dataset.py``` càd un csv contenant une liste de tokens étiquettés.

Il est possible d'ajouter des termes à l'antidictionnaire : ces mots seront classés en "O" ou autre. Et PLACENAME contient les EN de lieux. Les dates sont extraites avec la regex DATE_pattern. 

Le programme a deux arguments optionnels :

 ```--writeconll``` qui écrit automatiquement le document de sortie au format CoNLL càd un tsv avec pour chaque ligne un seul token suivi de son étiquette correcte et de son étiquette prédite par le programme regex. Pour que ce fichier ne soit pas écrit il faut ajouter l'option : ```--no-writeconll```


```--confmatrixnorm``` qui écrit la matrice de confusion normalisée. Pour optenir la matrice non normalisée il faut ajouter l'option ```--no-confmatrixnorm```. 



## GROBID

## modèles de spaCy


La bibliothèque spaCy a ses propres modèles avec lesquels il est possible de faire de la reconnaissance d'EN : pour le français le modèle de base est [```fr_core_news_sm```]'(https://spacy.io/models/fr) entraîné sur les jeux de données Universal Dependencies French Sequoai et WikiNER notamment. 
Le programme standalone ```spacy_ner.py``` effectue l'extraction des EN d'un document en texte brut. 

Il est possible de choisir un autre modèle que celui proposer par défaut en passant en argument --model. L'argument --outpath permet d'enregister les noms extraits avec leur étiquette (formats de sortie acceptés : txt et csv/tsv )


```python programmes_standalone/spacy_ner.py data/doc.txt --model fr_core_news_sm --outpath out/extraction_spacy_fr.csv```


## Transformers

### Modèles pré-entraînés sans spécialisation sur nos données

De nombreux modèles Transformers sont disponibles pour la Reconnaissance d'EN sur [HuggingFace](https://huggingface.co/). Il est possible en quelques lignes de code d'effectuer une extraction simple. C'est ce qu'effectue le programme standalone ```testing_hf_ner.py``` qui fonctionne comme le programme précédent de spacy en ligne de commande comme dans l'exemple : 

```python programmes_standalone/testing_hf_ner.py data/doc.txt --model Jean-Baptiste/camembert-ner --outpath out/extraction_camembert.csv```

L'utilisation de ces modèles n'oblige pas de les avoir téléchargés puisque on peut les utiliser grâce à l'API de la bibliothèque Python ```transformers```. 

Les EN donnés en sortie sont souvent scindés en plusieurs groupes (nommés des tokens) car la cette tokenisation permet à un modèle de gérer les mots peu communs. Un underscore sert à marquer le début d'un mot dans une série de tokens.  

## Affinage de Transformers sur nos données

## Affinage avec spaCy-llm

## IA Génératives et prompt engineering

## IA génératives par API
