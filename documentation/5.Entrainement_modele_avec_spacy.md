# Entraînement d'un modèle sur nos données

La bibliothèque spaCy offre une chaîne de traitement pour simplifier l'entrainement de LLMs. 


A partir des paramètres de base tokenizer = "spacy et "train_tests_split" = True, le programme creation_dataset.py se charge de convertir les données annotées manuellement en jeux de données pour l'entrainement. 
Les données sont disponibles aussi en format csv (tableur). 

Pour entraîner un modèle à l'aide des modules de spaCy il faut procéder à quelques étapes : 

1. Chercher les configurations de base pour l'entrainement : un quickstart permet d'obtenir ces configurations de base dans la documentation de spaCy https://spacy.io/usage/training. Après sélection des paramètres de bases comme suit :
![image](documentation/images/quickstart_spacy.jpg)

Il faut télécharger le document généré 'base_config.cfg' dans le dossier de son choix. 

2. Ajout des chemins vers les jeux d'entrainement et de validation. Cette étape est manuelle : dans le document base_config.cfg, modifier les lignes après ```[paths]``` pour que les chemins train (entrainement) et dev(validation) correspondent aux documents au format spacy générés par ```creation_dataset.py```

3. Génération automatique du vrai document de configuration en ligne de commande 

```spacy init fill-config base_config.cfg config.cfg```

Cette commande génère un nouveau document de configuration ```config.cfg```. 

Il est recommandé de vérifier que les données aient été correctement converties à l'aide de la commande 
```spacy debug data config.cfg```

4. Modification des paramètres d'entrainement. Le document config.cfg contient maintenant les paramètres par défaut pour l'entrainement. Parmi ceux-ci, le nombre d'époques c'est-à-dire le nombre de fois où le modèle va passer sur l'intégralité des données, est placé à 100, ce qui est un nombre très élevé. 

Il est nécessaire qu'un modèle passe plusieurs fois sur des données pour affiner sa modélisation (sa représentation vectorielle des tokens) globale. C'est l'affinage des "poids" de chaque token par rapport à la tâche demandée (ici "ner" named entity recognition) qui permet au modèle de généraliser face à des nouvelles données, donc de produire des prédictions correctes. Si le modèle n'a pas été face aux données d'entraiment suffisamment de fois, ses prédictions restent imprécises. On parle dans ce cas de "sous apprentissage". Cependant, quand un modèle passe de trop nombreuses fois sur un même jeu de données finit par apprendre par coeur les données et de ne plus être capable de généraliser face à des données inconnues. C'est la raison pour laquelle le paramètre du nombre maximal d'époque est essentiel et nécessite d'effectuer plusieurs expérimentations afin de déterminer le meilleur apprentissage. 

Il existe des stratégies d'arrêt ou "early stopping" pour éviter le surapprentissage. Ces stratégies s'appuient les mesures de précision ou de rappel des prédictions faites sur le jeu d'évaluation. 

Dans notre cas je propose de limiter le nombre à 60 époques. Sur les données du Ritter avec les 50 pages annotées manuellement, le modèle est encore en sous-apprentissage à 20 époques et obtient des résultats satisfaisants à partir de 40 époques. 